{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from typing import List, Dict, Any, Optional, Union, Tuple\n",
    "\n",
    "class LLMFeaturePipeline:\n",
    "    \"\"\"\n",
    "    LLMé©±åŠ¨çš„ç‰¹å¾å·¥ç¨‹ç®¡é“ï¼Œå®ç°è¯¢é—®å»ºè®®-è·å¾—å»ºè®®-å®æ–½ä»£ç -è·å¾—æ–°ç‰¹å¾çš„å…¨æµç¨‹\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, llm_api_key: str, model: str = \"gpt-4\", verbose: bool = True, provider: str = \"openai\"):\n",
    "        \"\"\"\n",
    "        åˆå§‹åŒ–LLMç‰¹å¾å·¥ç¨‹ç®¡é“\n",
    "        \n",
    "        å‚æ•°:\n",
    "            llm_api_key: LLM APIå¯†é’¥\n",
    "            model: ä½¿ç”¨çš„LLMæ¨¡å‹\n",
    "            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯\n",
    "            provider: LLMæä¾›å•†ï¼Œæ”¯æŒ\"openai\"æˆ–\"gemini\"\n",
    "        \"\"\"\n",
    "        self.api_key = llm_api_key\n",
    "        self.model = model\n",
    "        self.verbose = verbose\n",
    "        self.provider = provider.lower()\n",
    "        self.setup_api()\n",
    "        self.feature_suggestions = []\n",
    "        self.implemented_features = {}\n",
    "        self.execution_history = []\n",
    "        \n",
    "    def setup_api(self):\n",
    "        \"\"\"\n",
    "        è®¾ç½®APIå®¢æˆ·ç«¯\n",
    "        \"\"\"\n",
    "        if self.provider == \"openai\":\n",
    "            try:\n",
    "                import openai\n",
    "                openai.api_key = self.api_key\n",
    "                self.client = openai\n",
    "                if self.verbose:\n",
    "                    print(\"âœ… OpenAI APIå®¢æˆ·ç«¯è®¾ç½®æˆåŠŸ\")\n",
    "            except ImportError:\n",
    "                raise ImportError(\"è¯·å®‰è£…openaiåº“: pip install openai\")\n",
    "        elif self.provider == \"gemini\":\n",
    "            try:\n",
    "                from google import genai\n",
    "                self.client = genai.Client(api_key=self.api_key)\n",
    "                if self.verbose:\n",
    "                    print(\"âœ… Gemini APIå®¢æˆ·ç«¯è®¾ç½®æˆåŠŸ\")\n",
    "            except ImportError:\n",
    "                raise ImportError(\"è¯·å®‰è£…google-generativeaiåº“: pip install google-generativeai\")\n",
    "        else:\n",
    "            raise ValueError(f\"ä¸æ”¯æŒçš„æä¾›å•†: {self.provider}ï¼Œç›®å‰æ”¯æŒ 'openai' æˆ– 'gemini'\")\n",
    "    \n",
    "    def call_llm(self, prompt: str, system_message: str = None) -> str:\n",
    "        \"\"\"\n",
    "        è°ƒç”¨LLM APIè·å–å›å¤\n",
    "        \n",
    "        å‚æ•°:\n",
    "            prompt: ç”¨æˆ·æç¤º\n",
    "            system_message: ç³»ç»Ÿæç¤º\n",
    "            \n",
    "        è¿”å›:\n",
    "            LLMå›å¤çš„å†…å®¹\n",
    "        \"\"\"\n",
    "        if self.provider == \"openai\":\n",
    "            messages = []\n",
    "            if system_message:\n",
    "                messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "            \n",
    "            messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "            \n",
    "            try:\n",
    "                response = self.client.ChatCompletion.create(\n",
    "                    model=self.model,\n",
    "                    messages=messages\n",
    "                )\n",
    "                return response.choices[0].message.content\n",
    "            except Exception as e:\n",
    "                if self.verbose:\n",
    "                    print(f\"âŒ APIè°ƒç”¨å¤±è´¥: {e}\")\n",
    "                time.sleep(2)  # ç­‰å¾…ä¸€ä¸‹å†é‡è¯•\n",
    "                try:\n",
    "                    response = self.client.ChatCompletion.create(\n",
    "                        model=self.model,\n",
    "                        messages=messages\n",
    "                    )\n",
    "                    return response.choices[0].message.content\n",
    "                except Exception as e2:\n",
    "                    print(f\"âŒ å†æ¬¡APIè°ƒç”¨å¤±è´¥: {e2}\")\n",
    "                    return \"APIè°ƒç”¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIå¯†é’¥ã€‚\"\n",
    "        \n",
    "        elif self.provider == \"gemini\":\n",
    "            try:\n",
    "                # æ„å»ºæç¤ºå†…å®¹\n",
    "                contents = prompt\n",
    "                \n",
    "                if system_message:\n",
    "                    from google.genai import types\n",
    "                    response = self.client.models.generate_content(\n",
    "                        model=self.model,\n",
    "                        contents=contents,    \n",
    "                        config=types.GenerateContentConfig(\n",
    "                            system_instruction=system_message)\n",
    "                    )\n",
    "                else:\n",
    "                    response = self.client.models.generate_content(\n",
    "                        model=self.model,\n",
    "                        contents=contents \n",
    "                    )\n",
    "                \n",
    "                return response.text\n",
    "                \n",
    "            except Exception as e:\n",
    "                if self.verbose:\n",
    "                    print(f\"âŒ Gemini APIè°ƒç”¨å¤±è´¥: {e}\")\n",
    "                time.sleep(2)  # ç­‰å¾…ä¸€ä¸‹å†é‡è¯•\n",
    "                \n",
    "                try:\n",
    "                    # ç®€åŒ–è¯·æ±‚å†å°è¯•\n",
    "                    response = self.client.models.generate_content(\n",
    "                        model=self.model, \n",
    "                        contents=prompt\n",
    "                    )\n",
    "                    return response.text\n",
    "                except Exception as e2:\n",
    "                    print(f\"âŒ Gemini APIå†æ¬¡è°ƒç”¨å¤±è´¥: {e2}\")\n",
    "                    return \"Gemini APIè°ƒç”¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIå¯†é’¥ã€‚\"\n",
    "        \n",
    "        return \"ä¸æ”¯æŒçš„æä¾›å•†\"\n",
    "\n",
    "    def parse_code_from_response(self, response: str) -> str:\n",
    "        \"\"\"\n",
    "        ä»LLMå›å¤ä¸­æå–Pythonä»£ç ï¼Œæ”¯æŒåµŒå¥—ä»£ç å—\n",
    "        \"\"\"\n",
    "        # å°è¯•åŒ¹é…æœ€å¤–å±‚çš„Pythonä»£ç å—\n",
    "        code_pattern = r\"```python(.*?)```\"\n",
    "        matches = re.findall(code_pattern, response, re.DOTALL)\n",
    "        \n",
    "        if matches:\n",
    "            # æ¸…ç†æå–çš„ä»£ç \n",
    "            extracted_code = matches[0].strip()\n",
    "            \n",
    "            # æ£€æŸ¥æ˜¯å¦æœ‰å†…éƒ¨ä»£ç å—æ ‡è®°ï¼Œå¹¶ç§»é™¤å®ƒä»¬\n",
    "            extracted_code = re.sub(r'```\\w*\\n', '', extracted_code)\n",
    "            extracted_code = extracted_code.replace('\\n```', '')\n",
    "            \n",
    "            return extracted_code\n",
    "        \n",
    "        # å¦‚æœæ²¡æœ‰Markdownæ ¼å¼ï¼Œå°è¯•æŸ¥æ‰¾å¯èƒ½çš„Pythonä»£ç éƒ¨åˆ†\n",
    "        if \"def \" in response and \"return\" in response:\n",
    "            code_start = response.find(\"def \")\n",
    "            \n",
    "            # æ‰¾åˆ°ä»£ç å—çš„ç»“æŸä½ç½®\n",
    "            code_lines = response[code_start:].split('\\n')\n",
    "            end_line = 0\n",
    "            indent_level = 0\n",
    "            in_function = False\n",
    "            \n",
    "            for i, line in enumerate(code_lines):\n",
    "                if line.strip().startswith(\"def \") and line.strip().endswith(\":\"):\n",
    "                    in_function = True\n",
    "                    indent_level = len(line) - len(line.lstrip())\n",
    "                    continue\n",
    "                    \n",
    "                if in_function:\n",
    "                    if line.strip() and not line.startswith(\" \" * (indent_level + 4)):\n",
    "                        # ç¼©è¿›å‡å°‘ï¼Œå¯èƒ½æ˜¯å‡½æ•°ç»“æŸ\n",
    "                        if i > 2:  # è‡³å°‘åŒ…å«å‡½æ•°å®šä¹‰å’Œä¸€è¡Œå‡½æ•°ä½“\n",
    "                            end_line = i\n",
    "                            break\n",
    "            \n",
    "            if end_line > 0:\n",
    "                extracted_code = \"\\n\".join(code_lines[:end_line])\n",
    "                return extracted_code\n",
    "            else:\n",
    "                return \"\\n\".join(code_lines)\n",
    "                \n",
    "        return \"\"\n",
    "    \n",
    "    def parse_json_from_response(self, response: str) -> Dict:\n",
    "        \"\"\"\n",
    "        ä»LLMå›å¤ä¸­æå–JSONå†…å®¹ï¼Œæ”¹è¿›çš„å¥å£®ç‰ˆæœ¬\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            print(\"\\n==== LLMåŸå§‹å“åº” ====\")\n",
    "            print(response)\n",
    "            print(\"=====================\\n\")\n",
    "        \n",
    "        # é¦–å…ˆå°è¯•ç›´æ¥è§£æå®Œæ•´å“åº”ä¸­çš„JSONéƒ¨åˆ†\n",
    "        try:\n",
    "            # æŸ¥æ‰¾æœ€å¤–å±‚çš„JSONç»“æ„\n",
    "            json_pattern = r\"```json(.*?)```\"\n",
    "            matches = re.findall(json_pattern, response, re.DOTALL)\n",
    "            \n",
    "            if matches:\n",
    "                # æå–JSONå­—ç¬¦ä¸²å¹¶æ¸…ç†\n",
    "                json_str = matches[0].strip()\n",
    "                \n",
    "                # æ›¿æ¢å†…åµŒçš„ä»£ç å—\n",
    "                code_pattern = r\"```python(.*?)```\"\n",
    "                json_str = re.sub(code_pattern, lambda m: json.dumps(m.group(1)), json_str)\n",
    "                \n",
    "                # æ ‡å‡†åŒ–æ¢è¡Œç¬¦å’Œç©ºæ ¼\n",
    "                json_str = re.sub(r'[\\r\\n\\t]+', ' ', json_str)\n",
    "                json_str = re.sub(r'\\s{2,}', ' ', json_str)\n",
    "                \n",
    "                # å°è¯•è§£æ\n",
    "                try:\n",
    "                    return json.loads(json_str)\n",
    "                except json.JSONDecodeError:\n",
    "                    # å°è¯•ä½¿ç”¨æ›´ä¸¥æ ¼çš„è§£ææ–¹å¼\n",
    "                    return self._extract_json_array_or_object(json_str)\n",
    "                    \n",
    "            # å°è¯•ä»æ•´ä¸ªæ–‡æœ¬ä¸­æå–JSONæ•°ç»„æˆ–å¯¹è±¡\n",
    "            return self._extract_json_array_or_object(response)\n",
    "        \n",
    "        except Exception as e:\n",
    "            if self.verbose:\n",
    "                print(f\"âš ï¸ JSONè§£æå¤±è´¥: {e}\")\n",
    "            return self._fallback_parse_suggestions(response)\n",
    "\n",
    "    def _extract_json_array_or_object(self, text: str) -> Dict:\n",
    "        \"\"\"\n",
    "        ä»æ–‡æœ¬ä¸­æå–JSONæ•°ç»„æˆ–å¯¹è±¡\n",
    "        \"\"\"\n",
    "        # æŸ¥æ‰¾JSONæ•°ç»„æ¨¡å¼ï¼š[...]\n",
    "        array_match = re.search(r'\\[\\s*\\{.*\\}\\s*\\]', text, re.DOTALL)\n",
    "        if array_match:\n",
    "            try:\n",
    "                return json.loads(array_match.group(0))\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "        \n",
    "        # æŸ¥æ‰¾JSONå¯¹è±¡æ¨¡å¼ï¼š{...}\n",
    "        object_match = re.search(r'\\{\\s*\".*\"\\s*:.*\\}', text, re.DOTALL)\n",
    "        if object_match:\n",
    "            try:\n",
    "                return json.loads(object_match.group(0))\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "        \n",
    "        # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œè¿”å›ç©ºç»“æœ\n",
    "        return {}\n",
    "\n",
    "    def _fallback_parse_suggestions(self, text: str) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        ä½œä¸ºæœ€åçš„æ‰‹æ®µï¼Œä»æ–‡æœ¬ä¸­æå–å»ºè®®\n",
    "        \"\"\"\n",
    "        suggestions = []\n",
    "        \n",
    "        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ä»æ–‡æœ¬ä¸­æå–å•ä¸ªå»ºè®®\n",
    "        suggestion_pattern = r'\"suggestion_id\":\\s*\"([^\"]+)\".*?\"description\":\\s*\"([^\"]+)\".*?\"rationale\":\\s*\"([^\"]+)\"'\n",
    "        matches = re.findall(suggestion_pattern, text, re.DOTALL)\n",
    "        \n",
    "        for i, match in enumerate(matches):\n",
    "            suggestion_id, description, rationale = match\n",
    "            \n",
    "            # ä¸ºæ¯ä¸ªåŒ¹é…é¡¹æå–ä»£ç å®ç°\n",
    "            implementation_pattern = r'\"implementation\":\\s*\"(.*?)\"'\n",
    "            impl_match = re.search(implementation_pattern, text[text.find(suggestion_id):], re.DOTALL)\n",
    "            implementation = impl_match.group(1) if impl_match else \"\"\n",
    "            \n",
    "            # æå–å—å½±å“çš„åˆ—\n",
    "            affected_cols_pattern = r'\"affected_columns\":\\s*\\[(.*?)\\]'\n",
    "            cols_match = re.search(affected_cols_pattern, text[text.find(suggestion_id):], re.DOTALL)\n",
    "            affected_columns = self._parse_string_array(cols_match.group(1)) if cols_match else []\n",
    "            \n",
    "            # æå–æ–°ç‰¹å¾\n",
    "            new_features_pattern = r'\"new_features\":\\s*\\[(.*?)\\]'\n",
    "            features_match = re.search(new_features_pattern, text[text.find(suggestion_id):], re.DOTALL)\n",
    "            new_features = self._parse_string_array(features_match.group(1)) if features_match else []\n",
    "            \n",
    "            suggestion = {\n",
    "                \"suggestion_id\": suggestion_id,\n",
    "                \"suggestion_type\": self._guess_suggestion_type(description),\n",
    "                \"description\": description,\n",
    "                \"rationale\": rationale,\n",
    "                \"implementation\": implementation,\n",
    "                \"affected_columns\": affected_columns,\n",
    "                \"new_features\": new_features\n",
    "            }\n",
    "            \n",
    "            suggestions.append(suggestion)\n",
    "        \n",
    "        if not suggestions:\n",
    "            # å¦‚æœä¸Šé¢çš„æ–¹æ³•éƒ½å¤±è´¥äº†ï¼Œå›é€€åˆ°åŸæ¥çš„æå–æ–¹æ³•\n",
    "            suggestions = self._extract_suggestions_from_text(text)\n",
    "        \n",
    "        return suggestions\n",
    "\n",
    "    def _parse_string_array(self, array_str: str) -> List[str]:\n",
    "        \"\"\"è§£æå­—ç¬¦ä¸²æ•°ç»„\"\"\"\n",
    "        values = []\n",
    "        for item in array_str.split(','):\n",
    "            item = item.strip().strip('\"\\'')\n",
    "            if item:\n",
    "                values.append(item)\n",
    "        return values\n",
    "\n",
    "    def get_dataframe_info(self, df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"\n",
    "        è·å–æ•°æ®å¸§çš„åŸºæœ¬ä¿¡æ¯\n",
    "        \n",
    "        å‚æ•°:\n",
    "            df: è¾“å…¥æ•°æ®å¸§\n",
    "            \n",
    "        è¿”å›:\n",
    "            æ•°æ®å¸§ä¿¡æ¯å­—å…¸\n",
    "        \"\"\"\n",
    "        info = {\n",
    "            \"shape\": df.shape,\n",
    "            \"columns\": df.columns.tolist(),\n",
    "            \"dtypes\": {col: str(dtype) for col, dtype in df.dtypes.items()},\n",
    "            \"missing_values\": {col: int(df[col].isna().sum()) for col in df.columns},\n",
    "            \"unique_values\": {col: int(df[col].nunique()) for col in df.columns}\n",
    "        }\n",
    "        \n",
    "        # å¯¹åˆ†ç±»ç‰¹å¾æ”¶é›†å€¼åˆ†å¸ƒ\n",
    "        cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "        if len(cat_cols) > 0:\n",
    "            info[\"categorical_distributions\"] = {}\n",
    "            for col in cat_cols:\n",
    "                if df[col].nunique() < 15:  # åªåŒ…æ‹¬è¾ƒå°‘å”¯ä¸€å€¼çš„ç‰¹å¾\n",
    "                    info[\"categorical_distributions\"][col] = df[col].value_counts().to_dict()\n",
    "        \n",
    "        # å¯¹æ•°å€¼ç‰¹å¾æ”¶é›†åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯\n",
    "        num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "        if len(num_cols) > 0:\n",
    "            info[\"numerical_statistics\"] = {}\n",
    "            for col in num_cols:\n",
    "                info[\"numerical_statistics\"][col] = {\n",
    "                    \"min\": float(df[col].min()) if not pd.isna(df[col].min()) else None,\n",
    "                    \"max\": float(df[col].max()) if not pd.isna(df[col].max()) else None,\n",
    "                    \"mean\": float(df[col].mean()) if not pd.isna(df[col].mean()) else None,\n",
    "                    \"median\": float(df[col].median()) if not pd.isna(df[col].median()) else None\n",
    "                }\n",
    "                \n",
    "        return info\n",
    "\n",
    "    def ask_for_feature_suggestions(self, df: pd.DataFrame, \n",
    "                                    task_description: str, \n",
    "                                    target_column: Optional[str] = None,\n",
    "                                    dataset_background: Optional[str] = None,\n",
    "                                    custom_prompt: Optional[str] = None) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        è¯¢é—®LLMæä¾›ç‰¹å¾å·¥ç¨‹å»ºè®®\n",
    "        \n",
    "        å‚æ•°:\n",
    "            df: è¾“å…¥æ•°æ®å¸§\n",
    "            task_description: ä»»åŠ¡æè¿°\n",
    "            target_column: ç›®æ ‡åˆ—åç§°\n",
    "            dataset_background: æ•°æ®é›†èƒŒæ™¯ä¿¡æ¯ï¼Œå¸®åŠ©æ¨¡å‹ç†è§£æ•°æ®\n",
    "            custom_prompt: è‡ªå®šä¹‰æç¤ºï¼ˆå¦‚æœéœ€è¦ï¼‰\n",
    "            \n",
    "        è¿”å›:\n",
    "            ç‰¹å¾å·¥ç¨‹å»ºè®®åˆ—è¡¨\n",
    "        \"\"\"\n",
    "        # å‡†å¤‡æ•°æ®å¸§ä¿¡æ¯\n",
    "        df_info = self.get_dataframe_info(df)\n",
    "        data_sample = df.head(3).to_dict() if df.shape[0] > 0 else {}\n",
    "        \n",
    "        system_message = \"\"\"ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç‰¹å¾å·¥ç¨‹ä¸“å®¶ï¼Œæ“…é•¿å‘ç°æ•°æ®ä¸­çš„æ¨¡å¼å’Œåˆ›å»ºæœ‰ä»·å€¼çš„ç‰¹å¾ã€‚\n",
    "è¯·æä¾›å…·ä½“ã€å¯æ‰§è¡Œçš„ç‰¹å¾å·¥ç¨‹å»ºè®®ï¼Œæ¯ä¸ªå»ºè®®éƒ½åº”åŒ…å«è¯¦ç»†çš„å®ç°æ–¹å¼ã€‚ä»¥JSONæ ¼å¼å›å¤ã€‚\"\"\"\n",
    "        \n",
    "        if custom_prompt:\n",
    "            prompt = custom_prompt\n",
    "        else:\n",
    "            background_section = \"\"\n",
    "            if dataset_background:\n",
    "                background_section = f\"\"\"\n",
    "æ•°æ®é›†èƒŒæ™¯ï¼š\n",
    "{dataset_background}\n",
    "\"\"\"\n",
    "\n",
    "            prompt = f\"\"\"\n",
    "æˆ‘æœ‰ä¸€ä¸ªæœºå™¨å­¦ä¹ é¡¹ç›®ï¼Œéœ€è¦ä½ å¸®æˆ‘è¿›è¡Œç‰¹å¾å·¥ç¨‹ã€‚\n",
    "            \n",
    "ä»»åŠ¡æè¿°ï¼š{task_description}\n",
    "\n",
    "{\"ç›®æ ‡åˆ—ï¼š\" + target_column if target_column else \"\"}\n",
    "{background_section}\n",
    "æ•°æ®é›†ä¿¡æ¯ï¼š\n",
    "- å½¢çŠ¶ï¼š{df_info['shape']}\n",
    "- åˆ—ï¼š{df_info['columns']}\n",
    "- æ•°æ®ç±»å‹ï¼š{df_info['dtypes']}\n",
    "- ç¼ºå¤±å€¼ï¼š{df_info['missing_values']}\n",
    "- å”¯ä¸€å€¼æ•°é‡ï¼š{df_info['unique_values']}\n",
    "\n",
    "åˆ†ç±»ç‰¹å¾åˆ†å¸ƒï¼š\n",
    "{json.dumps(df_info.get('categorical_distributions', {}), indent=2)}\n",
    "\n",
    "æ•°å€¼ç‰¹å¾ç»Ÿè®¡ï¼š\n",
    "{json.dumps(df_info.get('numerical_statistics', {}), indent=2)}\n",
    "\n",
    "æ•°æ®æ ·ä¾‹ï¼š\n",
    "{json.dumps(data_sample, indent=2)}\n",
    "\n",
    "è¯·æä¾›5-10ä¸ªæœ‰ä»·å€¼çš„ç‰¹å¾å·¥ç¨‹å»ºè®®ï¼ŒåŒ…æ‹¬ï¼š\n",
    "1. ç‰¹å¾è½¬æ¢ï¼ˆå¦‚äºŒå€¼åŒ–ã€æ ‡å‡†åŒ–ã€ç‹¬çƒ­ç¼–ç ç­‰ï¼‰\n",
    "2. ç‰¹å¾äº¤äº’ï¼ˆå¦‚ç‰¹å¾ç»„åˆã€æ¯”ç‡ç‰¹å¾ç­‰ï¼‰\n",
    "3. åŸºäºé¢†åŸŸçŸ¥è¯†çš„ç‰¹å¾ï¼ˆå¦‚æ—¶é—´ç‰¹å¾ã€æ–‡æœ¬ç‰¹å¾ç­‰ï¼‰\n",
    "\n",
    "å¯¹æ¯ä¸ªå»ºè®®ï¼Œè¯·æä¾›ä»¥ä¸‹ä¿¡æ¯ï¼Œä»¥JSONæ•°ç»„æ ¼å¼è¿”å›ï¼š\n",
    "[\n",
    "  {{\n",
    "    \"suggestion_id\": \"å”¯ä¸€æ ‡è¯†ç¬¦\",\n",
    "    \"suggestion_type\": \"è½¬æ¢|äº¤äº’|é¢†åŸŸçŸ¥è¯†|å…¶ä»–\",\n",
    "    \"description\": \"è¯¦ç»†çš„å»ºè®®æè¿°\",\n",
    "    \"rationale\": \"ä¸ºä»€ä¹ˆè¿™ä¸ªç‰¹å¾å¯èƒ½æœ‰ä»·å€¼\",\n",
    "    \"implementation\": \"Pythonä»£ç å®ç°ï¼ˆå¯ä½œä¸ºä¸€ä¸ªå‡½æ•°ï¼‰\",\n",
    "    \"affected_columns\": [\"å—å½±å“çš„åˆ—\"],\n",
    "    \"new_features\": [\"æ–°ç”Ÿæˆçš„ç‰¹å¾åç§°\"]\n",
    "  }},\n",
    "  ...\n",
    "]\n",
    "\"\"\"\n",
    "        if self.verbose:\n",
    "            print(\"ğŸ” æ­£åœ¨è¯¢é—®LLMæä¾›ç‰¹å¾å·¥ç¨‹å»ºè®®...\")\n",
    "            \n",
    "        response = self.call_llm(prompt, system_message)\n",
    "        \n",
    "        try:\n",
    "            suggestions = self.parse_json_from_response(response)\n",
    "            if isinstance(suggestions, list):\n",
    "                self.feature_suggestions = suggestions\n",
    "                if self.verbose:\n",
    "                    print(f\"âœ… æ”¶åˆ°{len(suggestions)}ä¸ªç‰¹å¾å·¥ç¨‹å»ºè®®\")\n",
    "                return suggestions\n",
    "            else:\n",
    "                if self.verbose:\n",
    "                    print(\"âš ï¸ LLMè¿”å›æ ¼å¼ä¸æ­£ç¡®ï¼Œå°è¯•æå–å»ºè®®\")\n",
    "                return self._extract_suggestions_from_text(response)\n",
    "        except Exception as e:\n",
    "            if self.verbose:\n",
    "                print(f\"âŒ è§£æå»ºè®®å¤±è´¥: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def _extract_suggestions_from_text(self, text: str) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        ä»æ–‡æœ¬å›å¤ä¸­æå–å»ºè®®\n",
    "        \n",
    "        å‚æ•°:\n",
    "            text: LLMå›å¤æ–‡æœ¬\n",
    "            \n",
    "        è¿”å›:\n",
    "            æå–çš„å»ºè®®åˆ—è¡¨\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            print(\"\\n==== å°è¯•ä»æ–‡æœ¬ä¸­æå–å»ºè®® ====\")\n",
    "            print(f\"æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦\")\n",
    "            print(\"å‰500ä¸ªå­—ç¬¦é¢„è§ˆ:\")\n",
    "            print(text[:500] + \"...\" if len(text) > 500 else text)\n",
    "            print(\"============================\\n\")\n",
    "            \n",
    "        suggestions = []\n",
    "        \n",
    "        # å¯»æ‰¾å¯èƒ½çš„å»ºè®®éƒ¨åˆ†\n",
    "        suggestion_blocks = re.split(r'\\n\\d+[\\.\\)]\\s+', text)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"æ‰¾åˆ° {len(suggestion_blocks) - 1} ä¸ªæ½œåœ¨çš„å»ºè®®å—\")\n",
    "        \n",
    "        for i, block in enumerate(suggestion_blocks[1:], 1):  # è·³è¿‡ç¬¬ä¸€ä¸ªå¯èƒ½æ˜¯ä»‹ç»çš„éƒ¨åˆ†\n",
    "            if self.verbose and i <= 3:  # åªæ˜¾ç¤ºå‰3ä¸ªå—ä½œä¸ºç¤ºä¾‹\n",
    "                print(f\"\\n== å»ºè®®å— #{i} é¢„è§ˆ ==\")\n",
    "                preview = block[:200] + \"...\" if len(block) > 200 else block\n",
    "                print(preview)\n",
    "                print(\"===================\")\n",
    "                \n",
    "            lines = block.strip().split('\\n')\n",
    "            \n",
    "            if not lines:\n",
    "                continue\n",
    "                \n",
    "            # æå–å»ºè®®ä¿¡æ¯\n",
    "            title = lines[0].strip()\n",
    "            description = \"\\n\".join(lines[1:])\n",
    "            \n",
    "            # æå–ä»£ç éƒ¨åˆ†\n",
    "            code = self.parse_code_from_response(block)\n",
    "            \n",
    "            if self.verbose and code:\n",
    "                print(f\"ä»å»ºè®® #{i} ä¸­æå–åˆ°ä»£ç :\")\n",
    "                print(code[:200] + \"...\" if len(code) > 200 else code)\n",
    "            \n",
    "            suggestion = {\n",
    "                \"suggestion_id\": f\"auto_extracted_{i}\",\n",
    "                \"suggestion_type\": self._guess_suggestion_type(title),\n",
    "                \"description\": title,\n",
    "                \"rationale\": description,\n",
    "                \"implementation\": code if code else \"# éœ€è¦æ‰‹åŠ¨å®ç°\",\n",
    "                \"affected_columns\": [],\n",
    "                \"new_features\": []\n",
    "            }\n",
    "            \n",
    "            suggestions.append(suggestion)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"ğŸ“ ä»æ–‡æœ¬ä¸­æå–äº†{len(suggestions)}ä¸ªå»ºè®®\")\n",
    "            \n",
    "        self.feature_suggestions = suggestions\n",
    "        return suggestions\n",
    "    \n",
    "    def _guess_suggestion_type(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        æ ¹æ®æ–‡æœ¬çŒœæµ‹å»ºè®®ç±»å‹\n",
    "        \n",
    "        å‚æ•°:\n",
    "            text: å»ºè®®æ–‡æœ¬\n",
    "            \n",
    "        è¿”å›:\n",
    "            çŒœæµ‹çš„å»ºè®®ç±»å‹\n",
    "        \"\"\"\n",
    "        text = text.lower()\n",
    "        \n",
    "        if any(word in text for word in [\"äº¤äº’\", \"ç»„åˆ\", \"ä¹˜ç§¯\", \"æ¯”ç‡\", \"interaction\"]):\n",
    "            return \"äº¤äº’\"\n",
    "        elif any(word in text for word in [\"æ ‡å‡†åŒ–\", \"å½’ä¸€åŒ–\", \"ç¼–ç \", \"äºŒå€¼åŒ–\", \"transform\", \"encoding\"]):\n",
    "            return \"è½¬æ¢\"\n",
    "        elif any(word in text for word in [\"é¢†åŸŸ\", \"çŸ¥è¯†\", \"domain\", \"knowledge\"]):\n",
    "            return \"é¢†åŸŸçŸ¥è¯†\"\n",
    "        else:\n",
    "            return \"å…¶ä»–\"\n",
    "        \n",
    "    def implement_feature_suggestion(self, df: pd.DataFrame, suggestion_id: str) -> Tuple[pd.DataFrame, Dict]:\n",
    "        \"\"\"\n",
    "        å®ç°ç‰¹å®šçš„ç‰¹å¾å·¥ç¨‹å»ºè®®ï¼Œå¢å¼ºç‰ˆ\n",
    "        \"\"\"\n",
    "        # æŸ¥æ‰¾å¯¹åº”çš„å»ºè®®\n",
    "        suggestion = None\n",
    "        for s in self.feature_suggestions:\n",
    "            if s.get(\"suggestion_id\") == suggestion_id:\n",
    "                suggestion = s\n",
    "                break\n",
    "                \n",
    "        if not suggestion:\n",
    "            if self.verbose:\n",
    "                print(f\"âŒ æ‰¾ä¸åˆ°IDä¸º{suggestion_id}çš„å»ºè®®\")\n",
    "            return df, {\"status\": \"error\", \"message\": f\"æ‰¾ä¸åˆ°IDä¸º{suggestion_id}çš„å»ºè®®\"}\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"ğŸ”§ æ­£åœ¨å®ç°å»ºè®®: {suggestion.get('description', suggestion_id)}\")\n",
    "        \n",
    "        # æå–å®ç°ä»£ç å¹¶æ¸…ç†\n",
    "        implementation_code = suggestion.get(\"implementation\", \"\")\n",
    "        \n",
    "        # æ¸…ç†ä»£ç ä¸­çš„Markdownæ ‡è®°å’Œç‰¹æ®Šå­—ç¬¦\n",
    "        implementation_code = self._clean_implementation_code(implementation_code)\n",
    "        \n",
    "        if not implementation_code or implementation_code == \"# éœ€è¦æ‰‹åŠ¨å®ç°\":\n",
    "            # å¦‚æœæ²¡æœ‰å®ç°ä»£ç ï¼Œè¯·æ±‚LLMç”Ÿæˆ\n",
    "            if self.verbose:\n",
    "                print(\"ğŸ“ å»ºè®®ä¸­æ²¡æœ‰å®ç°ä»£ç ï¼Œæ­£åœ¨è¯·æ±‚LLMç”Ÿæˆ...\")\n",
    "            \n",
    "            implementation_code = self._generate_implementation_code(df, suggestion)\n",
    "        \n",
    "        # ç¡®ä¿ä»£ç æ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œå¦‚æœä¸æ˜¯åˆ™åŒ…è£…å®ƒ\n",
    "        if not implementation_code.strip().startswith(\"def \"):\n",
    "            function_name = f\"feature_{suggestion_id.replace('-', '_').replace('.', '_')}\"\n",
    "            \n",
    "            # æ£€æŸ¥ä»£ç æ˜¯å¦å·²ç»åŒ…å«å‡½æ•°è°ƒç”¨\n",
    "            if \"df = \" in implementation_code or \"return df\" in implementation_code:\n",
    "                # å·²ç»åŒ…å«å¤„ç†é€»è¾‘ï¼Œåªéœ€è¦åŒ…è£…æˆå‡½æ•°\n",
    "                implementation_code = f\"def {function_name}(df):\\n\" + \"\\n\".join(\n",
    "                    f\"    {line}\" for line in implementation_code.split(\"\\n\")\n",
    "                )\n",
    "            else:\n",
    "                # å¯èƒ½åªæ˜¯ä¸€äº›æ“ä½œæ­¥éª¤ï¼Œéœ€è¦æ·»åŠ DataFrameå¤„ç†é€»è¾‘\n",
    "                implementation_code = f\"\"\"def {function_name}(df):\n",
    "        df_result = df.copy()\n",
    "        \n",
    "        # å®ç°ç‰¹å¾å·¥ç¨‹é€»è¾‘\n",
    "        {implementation_code.strip()}\n",
    "        \n",
    "        return df_result\"\"\"\n",
    "        \n",
    "            # ç¡®ä¿æœ‰è¿”å›è¯­å¥\n",
    "            if \"return\" not in implementation_code:\n",
    "                implementation_code = implementation_code.rstrip() + \"\\n    return df\"\n",
    "        \n",
    "        # å¤„ç†ä¿ç•™åŸå§‹ç‰¹å¾çš„é€»è¾‘\n",
    "        keep_original = suggestion.get(\"keep_original\", True)  # é»˜è®¤ä¿ç•™åŸå§‹ç‰¹å¾\n",
    "        affected_columns = suggestion.get(\"affected_columns\", [])\n",
    "        \n",
    "        # æ·»åŠ å®‰å…¨æ£€æŸ¥ï¼Œç¡®ä¿å‡½æ•°è¯­æ³•æ­£ç¡®\n",
    "        implementation_code = self._add_safety_checks(implementation_code, affected_columns)\n",
    "        \n",
    "        # å°è¯•æ‰§è¡Œå®ç°ä»£ç \n",
    "        return self._execute_implementation(df, suggestion, implementation_code, keep_original, affected_columns)\n",
    "\n",
    "    def _clean_implementation_code(self, code: str) -> str:\n",
    "        \"\"\"æ¸…ç†å®ç°ä»£ç ä¸­çš„Markdownæ ‡è®°å’Œç‰¹æ®Šå­—ç¬¦\"\"\"\n",
    "        # ç§»é™¤Markdownä»£ç å—æ ‡è®°\n",
    "        code = re.sub(r'```python\\s*', '', code)\n",
    "        code = re.sub(r'\\s*```', '', code)\n",
    "        \n",
    "        # ç§»é™¤å¯èƒ½çš„å¼•å·è½¬ä¹‰\n",
    "        code = code.replace('\\\\\"', '\"')\n",
    "        \n",
    "        # ç§»é™¤å¼€å¤´å’Œç»“å°¾çš„ç©ºç™½\n",
    "        return code.strip()\n",
    "\n",
    "    def _add_safety_checks(self, code: str, affected_columns: List[str]) -> str:\n",
    "        \"\"\"æ·»åŠ å®‰å…¨æ£€æŸ¥ç¡®ä¿ä»£ç æ­£ç¡®æ‰§è¡Œ\"\"\"\n",
    "        # è·å–å‡½æ•°å\n",
    "        func_name = re.search(r'def\\s+(\\w+)', code).group(1)\n",
    "        \n",
    "        # æ·»åŠ åˆ—å­˜åœ¨æ€§æ£€æŸ¥\n",
    "        column_checks = []\n",
    "        for col in affected_columns:\n",
    "            if col:\n",
    "                column_checks.append(f'    # æ£€æŸ¥åˆ— \"{col}\" æ˜¯å¦å­˜åœ¨\\n    if \"{col}\" not in df.columns:\\n        print(f\"è­¦å‘Š: åˆ— \\\\\"{col}\\\\\" ä¸å­˜åœ¨ï¼Œè·³è¿‡è¯¥åˆ—å¤„ç†\")\\n        return df')\n",
    "        \n",
    "        # å¦‚æœæœ‰éœ€è¦æ£€æŸ¥çš„åˆ—ï¼Œæ’å…¥æ£€æŸ¥ä»£ç \n",
    "        if column_checks:\n",
    "            # æŸ¥æ‰¾å‡½æ•°å®šä¹‰çš„æœ«å°¾\n",
    "            func_def_end = code.find(\":\", code.find(\"def \")) + 1\n",
    "            \n",
    "            # æ’å…¥å®‰å…¨æ£€æŸ¥ä»£ç \n",
    "            safety_code = \"\\n\" + \"\\n\".join(column_checks) + \"\\n    \\n    # åˆ›å»ºå‰¯æœ¬é¿å…ä¿®æ”¹åŸå§‹æ•°æ®\\n    df = df.copy()\\n\"\n",
    "            code = code[:func_def_end] + safety_code + code[func_def_end:]\n",
    "        \n",
    "        return code\n",
    "\n",
    "    def _execute_implementation(self, df, suggestion, implementation_code, keep_original, affected_columns, is_retry=False):\n",
    "        \"\"\"\n",
    "        æ‰§è¡Œç‰¹å¾å·¥ç¨‹å®ç°ä»£ç \n",
    "        \n",
    "        å‚æ•°:\n",
    "            df: è¾“å…¥æ•°æ®å¸§\n",
    "            suggestion: ç‰¹å¾å»ºè®®å­—å…¸\n",
    "            implementation_code: è¦æ‰§è¡Œçš„ä»£ç \n",
    "            keep_original: æ˜¯å¦ä¿ç•™åŸå§‹ç‰¹å¾\n",
    "            affected_columns: å—å½±å“çš„åˆ—\n",
    "            is_retry: æ˜¯å¦ä¸ºé‡è¯•æ‰§è¡Œ\n",
    "            \n",
    "        è¿”å›:\n",
    "            (æ›´æ–°çš„æ•°æ®å¸§, å®ç°ç»“æœä¿¡æ¯)\n",
    "        \"\"\"\n",
    "        suggestion_id = suggestion.get(\"suggestion_id\")\n",
    "        \n",
    "        try:\n",
    "            # åˆ›å»ºæœ¬åœ°å‘½åç©ºé—´\n",
    "            local_namespace = {\"pd\": pd, \"np\": np}\n",
    "            \n",
    "            # æ‰§è¡Œä»£ç \n",
    "            exec(implementation_code, globals(), local_namespace)\n",
    "            \n",
    "            # è·å–å‡½æ•°å\n",
    "            function_name = None\n",
    "            for name, obj in local_namespace.items():\n",
    "                if callable(obj) and name not in [\"pd\", \"np\"]:\n",
    "                    function_name = name\n",
    "                    break\n",
    "            \n",
    "            if not function_name:\n",
    "                raise ValueError(\"æ— æ³•æ‰¾åˆ°å®ç°å‡½æ•°\")\n",
    "            \n",
    "            # è°ƒç”¨å‡½æ•°\n",
    "            result_df = local_namespace[function_name](df)\n",
    "            \n",
    "            # éªŒè¯ç»“æœ\n",
    "            if not isinstance(result_df, pd.DataFrame):\n",
    "                raise TypeError(\"å®ç°å‡½æ•°æœªè¿”å›DataFrame\")\n",
    "            \n",
    "            # å¦‚æœæŒ‡å®šä¸ä¿ç•™åŸå§‹ç‰¹å¾ï¼Œåˆ™ç§»é™¤\n",
    "            if not keep_original and affected_columns:\n",
    "                # ç¡®ä¿æ‰€æœ‰å—å½±å“çš„åˆ—éƒ½è¢«è½¬æ¢åæ‰ç§»é™¤\n",
    "                safe_to_remove = all(col in df.columns for col in affected_columns)\n",
    "                if safe_to_remove:\n",
    "                    for col in affected_columns:\n",
    "                        if col in result_df.columns and col not in suggestion.get(\"new_features\", []):\n",
    "                            if self.verbose:\n",
    "                                print(f\"ğŸ—‘ï¸ æ ¹æ®å»ºè®®ç§»é™¤åŸå§‹ç‰¹å¾: {col}\")\n",
    "                            result_df = result_df.drop(col, axis=1)\n",
    "            \n",
    "            # ç¡®å®šæ–°å¢çš„ç‰¹å¾\n",
    "            new_features = list(set(result_df.columns) - set(df.columns))\n",
    "            \n",
    "            # è®°å½•å®ç°ç»“æœ\n",
    "            implementation_result = {\n",
    "                \"suggestion_id\": suggestion_id,\n",
    "                \"status\": \"success\",\n",
    "                \"description\": suggestion.get(\"description\", \"\"),\n",
    "                \"code\": implementation_code,\n",
    "                \"new_features\": new_features,\n",
    "                \"removed_features\": [col for col in df.columns if col not in result_df.columns],\n",
    "                \"keep_original\": keep_original,\n",
    "                \"keep_original_reason\": suggestion.get(\"keep_original_reason\", \"\"),\n",
    "                \"error\": None\n",
    "            }\n",
    "            \n",
    "            self.implemented_features[suggestion_id] = implementation_result\n",
    "            self.execution_history.append(implementation_result)\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(f\"âœ… {'ä½¿ç”¨ä¿®å¤åçš„ä»£ç ' if is_retry else ''}æˆåŠŸå®ç°å»ºè®®ï¼Œæ–°å¢{len(new_features)}ä¸ªç‰¹å¾: {new_features}\")\n",
    "                if implementation_result[\"removed_features\"]:\n",
    "                    print(f\"ğŸ—‘ï¸ ç§»é™¤äº†{len(implementation_result['removed_features'])}ä¸ªåŸå§‹ç‰¹å¾: {implementation_result['removed_features']}\")\n",
    "            \n",
    "            return result_df, implementation_result\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_message = str(e)\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(f\"âŒ å®ç°å»ºè®®æ—¶å‡ºé”™: {error_message}\")\n",
    "            \n",
    "            # å¦‚æœä¸æ˜¯é‡è¯•ï¼Œå°è¯•ä¿®å¤ä»£ç å¹¶é‡è¯•\n",
    "            if not is_retry:\n",
    "                # å°è¯•ä¿®å¤ä»£ç \n",
    "                fixed_code = self._fix_implementation_code(implementation_code, error_message, df)\n",
    "                \n",
    "                # å¦‚æœä¿®å¤äº†ä»£ç ï¼Œé‡æ–°å°è¯•\n",
    "                if fixed_code != implementation_code:\n",
    "                    if self.verbose:\n",
    "                        print(\"ğŸ”„ å°è¯•ä½¿ç”¨ä¿®å¤çš„ä»£ç é‡æ–°å®ç°...\")\n",
    "                    \n",
    "                    # é€’å½’è°ƒç”¨ï¼Œä½†æ ‡è®°ä¸ºé‡è¯•ï¼Œé˜²æ­¢æ— é™å¾ªç¯\n",
    "                    return self._execute_implementation(df, suggestion, fixed_code, keep_original, affected_columns, is_retry=True)\n",
    "            \n",
    "            # è®°å½•å¤±è´¥\n",
    "            implementation_result = {\n",
    "                \"suggestion_id\": suggestion_id,\n",
    "                \"status\": \"error\",\n",
    "                \"description\": suggestion.get(\"description\", \"\"),\n",
    "                \"code\": implementation_code,\n",
    "                \"new_features\": [],\n",
    "                \"removed_features\": [],\n",
    "                \"keep_original\": keep_original,\n",
    "                \"keep_original_reason\": suggestion.get(\"keep_original_reason\", \"\"),\n",
    "                \"error\": error_message if is_retry else f\"åˆå§‹é”™è¯¯: {error_message}\"\n",
    "            }\n",
    "            \n",
    "            self.implemented_features[suggestion_id] = implementation_result\n",
    "            self.execution_history.append(implementation_result)\n",
    "            \n",
    "            return df, implementation_result\n",
    "    \n",
    "    def _generate_implementation_code(self, df: pd.DataFrame, suggestion: Dict) -> str:\n",
    "        \"\"\"\n",
    "        ä¸ºå»ºè®®ç”Ÿæˆå®ç°ä»£ç \n",
    "        \n",
    "        å‚æ•°:\n",
    "            df: è¾“å…¥æ•°æ®å¸§\n",
    "            suggestion: å»ºè®®è¯¦æƒ…\n",
    "            \n",
    "        è¿”å›:\n",
    "            å®ç°ä»£ç \n",
    "        \"\"\"\n",
    "        # è·å–æ•°æ®å¸§ä¿¡æ¯\n",
    "        df_info = self.get_dataframe_info(df)\n",
    "        \n",
    "        system_message = \"\"\"ä½ æ˜¯ä¸€ä½ç‰¹å¾å·¥ç¨‹ä¸“å®¶ï¼Œèƒ½å¤Ÿç¼–å†™é«˜è´¨é‡çš„Pythonä»£ç æ¥å®ç°ç‰¹å¾å·¥ç¨‹ã€‚\n",
    "è¯·æä¾›å®Œæ•´å¯æ‰§è¡Œçš„Pythonå‡½æ•°ï¼Œé’ˆå¯¹è¾“å…¥çš„DataFrameå®ç°æ‰€éœ€çš„ç‰¹å¾å·¥ç¨‹ã€‚\n",
    "ä»£ç åº”è¯¥æ˜¯å¥å£®çš„ï¼Œèƒ½å¤Ÿå¤„ç†è¾¹ç¼˜æƒ…å†µï¼Œå¦‚ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼ã€‚\"\"\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "è¯·ä¸ºä»¥ä¸‹ç‰¹å¾å·¥ç¨‹å»ºè®®ç¼–å†™Pythonå®ç°ä»£ç :\n",
    "\n",
    "å»ºè®®æè¿°: {suggestion.get('description', '')}\n",
    "å»ºè®®ç†ç”±: {suggestion.get('rationale', '')}\n",
    "å»ºè®®ç±»å‹: {suggestion.get('suggestion_type', 'æœªçŸ¥')}\n",
    "å—å½±å“çš„åˆ—: {suggestion.get('affected_columns', [])}\n",
    "é¢„æœŸæ–°ç‰¹å¾: {suggestion.get('new_features', [])}\n",
    "\n",
    "æ•°æ®é›†ä¿¡æ¯:\n",
    "- å½¢çŠ¶: {df_info['shape']}\n",
    "- åˆ—: {df_info['columns']}\n",
    "- æ•°æ®ç±»å‹: {df_info['dtypes']}\n",
    "\n",
    "è¯·ç¼–å†™ä¸€ä¸ªåä¸º`implement_feature`çš„Pythonå‡½æ•°ï¼Œè¯¥å‡½æ•°:\n",
    "1. æ¥å—ä¸€ä¸ªpandas DataFrameä½œä¸ºè¾“å…¥\n",
    "2. å®ç°ä¸Šè¿°ç‰¹å¾å·¥ç¨‹å»ºè®®\n",
    "3. è¿”å›åŒ…å«æ–°ç‰¹å¾çš„DataFrame\n",
    "\n",
    "ä»£ç åº”è¯¥:\n",
    "- å¤„ç†å¯èƒ½çš„ç¼ºå¤±å€¼\n",
    "- åŒ…å«é€‚å½“çš„æ³¨é‡Š\n",
    "- éµå¾ªPythonæœ€ä½³å®è·µ\n",
    "- ä¸ä½¿ç”¨å¤–éƒ¨æ•°æ®æº\n",
    "\n",
    "è¯·ä»…è¿”å›Pythonä»£ç ï¼Œä¸éœ€è¦è§£é‡Šã€‚\n",
    "\"\"\"\n",
    "        \n",
    "        response = self.call_llm(prompt, system_message)\n",
    "        code = self.parse_code_from_response(response)\n",
    "        \n",
    "        if not code:\n",
    "            # å¦‚æœæ²¡æœ‰æå–åˆ°ä»£ç ï¼Œä½¿ç”¨ç®€å•çš„æ¨¡æ¿\n",
    "            code = f\"\"\"def implement_feature(df):\n",
    "    \\\"\\\"\\\"\n",
    "    å®ç°: {suggestion.get('description', '')}\n",
    "    \n",
    "    å‚æ•°:\n",
    "        df: è¾“å…¥æ•°æ®å¸§\n",
    "        \n",
    "    è¿”å›:\n",
    "        åŒ…å«æ–°ç‰¹å¾çš„æ•°æ®å¸§\n",
    "    \\\"\\\"\\\"\n",
    "    df_result = df.copy()\n",
    "    \n",
    "    # TODO: å®ç°ç‰¹å¾å·¥ç¨‹é€»è¾‘\n",
    "    \n",
    "    return df_result\n",
    "\"\"\"\n",
    "        \n",
    "        return code\n",
    "    \n",
    "    def _fix_implementation_code(self, code: str, error_message: str, df: pd.DataFrame) -> str:\n",
    "        \"\"\"\n",
    "        ä¿®å¤å®ç°ä»£ç ä¸­çš„é”™è¯¯\n",
    "        \n",
    "        å‚æ•°:\n",
    "            code: åŸå§‹ä»£ç \n",
    "            error_message: é”™è¯¯ä¿¡æ¯\n",
    "            df: è¾“å…¥æ•°æ®å¸§\n",
    "            \n",
    "        è¿”å›:\n",
    "            ä¿®å¤åçš„ä»£ç \n",
    "        \"\"\"\n",
    "        df_info = self.get_dataframe_info(df)\n",
    "        \n",
    "        system_message = \"\"\"ä½ æ˜¯ä¸€ä½Pythonä¸“å®¶ï¼Œèƒ½å¤Ÿä¿®å¤ä»£ç ä¸­çš„é”™è¯¯ã€‚\n",
    "è¯·åˆ†æé”™è¯¯ä¿¡æ¯ï¼Œå¹¶æä¾›ä¿®å¤åçš„ä»£ç ã€‚åªè¿”å›å®Œæ•´çš„ã€ä¿®å¤åçš„ä»£ç ï¼Œä¸éœ€è¦è§£é‡Šã€‚\"\"\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "ä»¥ä¸‹ä»£ç åœ¨æ‰§è¡Œæ—¶å‡ºç°é”™è¯¯:\n",
    "\n",
    "```python\n",
    "{code}\n",
    "```\n",
    "\n",
    "é”™è¯¯ä¿¡æ¯:\n",
    "{error_message}\n",
    "\n",
    "æ•°æ®é›†ä¿¡æ¯:\n",
    "- å½¢çŠ¶: {df_info['shape']}\n",
    "- åˆ—: {df_info['columns']}\n",
    "- æ•°æ®ç±»å‹: {df_info['dtypes']}\n",
    "\n",
    "è¯·ä¿®å¤ä»£ç ä¸­çš„é”™è¯¯ã€‚åªè¿”å›å®Œæ•´çš„ã€ä¿®å¤åçš„ä»£ç ï¼Œä¸è¦æœ‰ä»»ä½•è§£é‡Šã€‚\n",
    "\"\"\"\n",
    "        \n",
    "        response = self.call_llm(prompt, system_message)\n",
    "        fixed_code = self.parse_code_from_response(response)\n",
    "        \n",
    "        if not fixed_code:\n",
    "            # å¦‚æœæ²¡æœ‰æå–åˆ°ä»£ç ï¼Œè¿”å›åŸå§‹ä»£ç \n",
    "            return code\n",
    "            \n",
    "        return fixed_code\n",
    "    \n",
    "    def implement_all_suggestions(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        å®ç°æ‰€æœ‰çš„ç‰¹å¾å·¥ç¨‹å»ºè®®\n",
    "        \n",
    "        å‚æ•°:\n",
    "            df: è¾“å…¥æ•°æ®å¸§\n",
    "            \n",
    "        è¿”å›:\n",
    "            åŒ…å«æ‰€æœ‰æ–°ç‰¹å¾çš„æ•°æ®å¸§\n",
    "        \"\"\"\n",
    "        if not self.feature_suggestions:\n",
    "            if self.verbose:\n",
    "                print(\"âš ï¸ æ²¡æœ‰å¯ç”¨çš„ç‰¹å¾å·¥ç¨‹å»ºè®®\")\n",
    "            return df\n",
    "            \n",
    "        result_df = df.copy()\n",
    "        successful_count = 0\n",
    "        \n",
    "        for suggestion in self.feature_suggestions:\n",
    "            suggestion_id = suggestion.get(\"suggestion_id\")\n",
    "            \n",
    "            if not suggestion_id:\n",
    "                continue\n",
    "                \n",
    "            if self.verbose:\n",
    "                print(f\"ğŸ” å®ç°å»ºè®® {suggestion_id}: {suggestion.get('description', '')}\")\n",
    "                \n",
    "            try:\n",
    "                result_df, impl_result = self.implement_feature_suggestion(result_df, suggestion_id)\n",
    "                \n",
    "                if impl_result[\"status\"] == \"success\":\n",
    "                    successful_count += 1\n",
    "            except Exception as e:\n",
    "                if self.verbose:\n",
    "                    print(f\"âŒ å®ç°å»ºè®® {suggestion_id} æ—¶å‡ºç°æœªå¤„ç†çš„é”™è¯¯: {e}\")\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"âœ… æˆåŠŸå®ç° {successful_count}/{len(self.feature_suggestions)} ä¸ªå»ºè®®\")\n",
    "            print(f\"ğŸ†• æ–°ç‰¹å¾æ€»æ•°: {len(result_df.columns) - len(df.columns)}\")\n",
    "            \n",
    "        return result_df\n",
    "    \n",
    "    def custom_feature_request(self, df: pd.DataFrame, feature_description: str) -> Tuple[pd.DataFrame, Dict]:\n",
    "        \"\"\"\n",
    "        æ ¹æ®è‡ªå®šä¹‰æè¿°åˆ›å»ºç‰¹å¾\n",
    "        \n",
    "        å‚æ•°:\n",
    "            df: è¾“å…¥æ•°æ®å¸§\n",
    "            feature_description: ç‰¹å¾æè¿°\n",
    "            \n",
    "        è¿”å›:\n",
    "            (æ›´æ–°çš„æ•°æ®å¸§, å®ç°ç»“æœä¿¡æ¯)\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            print(f\"ğŸ” æ­£åœ¨å¤„ç†è‡ªå®šä¹‰ç‰¹å¾è¯·æ±‚: {feature_description}\")\n",
    "            \n",
    "        df_info = self.get_dataframe_info(df)\n",
    "        \n",
    "        system_message = \"\"\"ä½ æ˜¯ä¸€ä½ç‰¹å¾å·¥ç¨‹ä¸“å®¶ï¼Œèƒ½å¤Ÿæ ¹æ®æè¿°åˆ›å»ºæœ‰ä»·å€¼çš„ç‰¹å¾ã€‚\n",
    "è¯·æä¾›å®Œæ•´å¯æ‰§è¡Œçš„Pythonå‡½æ•°ï¼Œå®ç°æ‰€éœ€çš„ç‰¹å¾å·¥ç¨‹ã€‚\"\"\"\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "è¯·æ ¹æ®ä»¥ä¸‹æè¿°åˆ›å»ºæ–°ç‰¹å¾:\n",
    "\n",
    "ç‰¹å¾æè¿°: {feature_description}\n",
    "\n",
    "æ•°æ®é›†ä¿¡æ¯:\n",
    "- å½¢çŠ¶: {df_info['shape']}\n",
    "- åˆ—: {df_info['columns']}\n",
    "- æ•°æ®ç±»å‹: {df_info['dtypes']}\n",
    "\n",
    "è¯·ç¼–å†™ä¸€ä¸ªåä¸º`create_custom_feature`çš„Pythonå‡½æ•°ï¼Œè¯¥å‡½æ•°:\n",
    "1. æ¥å—ä¸€ä¸ªpandas DataFrameä½œä¸ºè¾“å…¥\n",
    "2. æ ¹æ®ä¸Šè¿°æè¿°åˆ›å»ºæ–°ç‰¹å¾\n",
    "3. è¿”å›åŒ…å«æ–°ç‰¹å¾çš„DataFrame\n",
    "\n",
    "ä»£ç åº”è¯¥:\n",
    "- å¤„ç†å¯èƒ½çš„ç¼ºå¤±å€¼\n",
    "- åŒ…å«é€‚å½“çš„æ³¨é‡Š\n",
    "- éµå¾ªPythonæœ€ä½³å®è·µ\n",
    "\n",
    "è¯·ä»…è¿”å›Pythonä»£ç ï¼Œä¸éœ€è¦è§£é‡Šã€‚\n",
    "\"\"\"\n",
    "        \n",
    "        response = self.call_llm(prompt, system_message)\n",
    "        implementation_code = self.parse_code_from_response(response)\n",
    "        \n",
    "        # ç”Ÿæˆå”¯ä¸€ID\n",
    "        suggestion_id = f\"custom_{int(time.time())}\"\n",
    "        \n",
    "        # åˆ›å»ºå»ºè®®å¯¹è±¡\n",
    "        suggestion = {\n",
    "            \"suggestion_id\": suggestion_id,\n",
    "            \"suggestion_type\": \"è‡ªå®šä¹‰\",\n",
    "            \"description\": feature_description,\n",
    "            \"rationale\": \"ç”¨æˆ·è‡ªå®šä¹‰ç‰¹å¾\",\n",
    "            \"implementation\": implementation_code,\n",
    "            \"affected_columns\": [],\n",
    "            \"new_features\": []\n",
    "        }\n",
    "        \n",
    "        # æ·»åŠ åˆ°å»ºè®®åˆ—è¡¨\n",
    "        self.feature_suggestions.append(suggestion)\n",
    "        \n",
    "        # å®ç°å»ºè®®\n",
    "        return self.implement_feature_suggestion(df, suggestion_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Gemini APIå®¢æˆ·ç«¯è®¾ç½®æˆåŠŸ\n"
     ]
    }
   ],
   "source": [
    "pipeline = LLMFeaturePipeline(llm_api_key=\"AIzaSyAw-q2h2gufVEhHiXWPHzTqZmqbvFnnfrY\", provider=\"gemini\", model=\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_eng = pd.read_pickle(\"train_eng.pkl\")\n",
    "\n",
    "# è¯»å– test_eng.pkl\n",
    "test_eng = pd.read_pickle(\"test_eng.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” æ­£åœ¨è¯¢é—®LLMæä¾›ç‰¹å¾å·¥ç¨‹å»ºè®®...\n",
      "\n",
      "==== LLMåŸå§‹å“åº” ====\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"suggestion_id\": \"FE1\",\n",
      "    \"suggestion_type\": \"è½¬æ¢\",\n",
      "    \"description\": \"å°†äºŒå…ƒåˆ†ç±»ç‰¹å¾è½¬æ¢ä¸ºæ•°å€¼å‹ (0, 1)\",\n",
      "    \"rationale\": \"æ–¹ä¾¿æ¨¡å‹å¤„ç†ï¼Œé¿å…æ¨¡å‹å¯¹ç±»åˆ«é¡ºåºæ•æ„Ÿã€‚\",\n",
      "    \"implementation\": \"```python\\ndef binary_encode(df, columns):\\n    for col in columns:\\n        df[col] = df[col].map({'N': 0, 'Y': 1, 'F':0, 'M':1, 'N':0, 'S':0.5, 'Y':1, 'C':0, 'D':1, 'CL':0.5})\\n    return df\\n```\",\n",
      "    \"affected_columns\": [\"Sex\", \"Ascites\", \"Hepatomegaly\", \"Spiders\", \"Edema\"],\n",
      "    \"new_features\": [\"Sex_encoded\", \"Ascites_encoded\", \"Hepatomegaly_encoded\", \"Spiders_encoded\", \"Edema_encoded\"]\n",
      "  },\n",
      "  {\n",
      "    \"suggestion_id\": \"FE2\",\n",
      "    \"suggestion_type\": \"è½¬æ¢\",\n",
      "    \"description\": \"å¯¹æ•°å€¼ç‰¹å¾è¿›è¡Œæ ‡å‡†åŒ–æˆ–å½’ä¸€åŒ–\",\n",
      "    \"rationale\": \"æ•°å€¼ç‰¹å¾èŒƒå›´å·®å¼‚è¾ƒå¤§ï¼Œæ ‡å‡†åŒ–å¯ä»¥æé«˜æ¨¡å‹çš„è®­ç»ƒæ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚\",\n",
      "    \"implementation\": \"```python\\nfrom sklearn.preprocessing import StandardScaler\\ndef standardize(df, columns):\\n    scaler = StandardScaler()\\n    df[columns] = scaler.fit_transform(df[columns])\\n    return df\\n```\",\n",
      "    \"affected_columns\": [\"Age\", \"Bilirubin\", \"Cholesterol\", \"Albumin\", \"Copper\", \"Alk_Phos\", \"SGOT\", \"Tryglicerides\", \"Platelets\", \"Prothrombin\"],\n",
      "    \"new_features\": [\"Age_std\", \"Bilirubin_std\", \"Cholesterol_std\", \"Albumin_std\", \"Copper_std\", \"Alk_Phos_std\", \"SGOT_std\", \"Tryglicerides_std\", \"Platelets_std\", \"Prothrombin_std\"]\n",
      "  },\n",
      "  {\n",
      "    \"suggestion_id\": \"FE3\",\n",
      "    \"suggestion_type\": \"è½¬æ¢\",\n",
      "    \"description\": \"å¯¹'Drug'ç‰¹å¾è¿›è¡Œç‹¬çƒ­ç¼–ç \",\n",
      "    \"rationale\": \"'Drug'æ˜¯ç±»åˆ«ç‰¹å¾ï¼Œç‹¬çƒ­ç¼–ç å¯ä»¥é¿å…æ¨¡å‹å°†ç±»åˆ«è¿›è¡Œæ’åºã€‚\",\n",
      "    \"implementation\": \"```python\\nfrom sklearn.preprocessing import OneHotEncoder\\ndef onehot_encode(df, column):\\n    encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\\n    encoded_data = encoder.fit_transform(df[[column]])\\n    encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out([column]))\\n    df = pd.concat([df, encoded_df], axis=1)\\n    return df\\n```\",\n",
      "    \"affected_columns\": [\"Drug\"],\n",
      "    \"new_features\": [\"Drug_Placebo\", \"Drug_D-penicillamine\"]\n",
      "  },\n",
      "  {\n",
      "    \"suggestion_id\": \"FE4\",\n",
      "    \"suggestion_type\": \"äº¤äº’\",\n",
      "    \"description\": \"åˆ›å»ºè‚åŠŸèƒ½æŒ‡æ ‡çš„æ¯”ç‡ç‰¹å¾\",\n",
      "    \"rationale\": \"æ¯”ç‡ç‰¹å¾å¯ä»¥åæ˜ ä¸åŒæŒ‡æ ‡ä¹‹é—´çš„å…³ç³»ï¼Œå¯èƒ½è•´å«é¢å¤–çš„ä¿¡æ¯ã€‚\",\n",
      "    \"implementation\": \"```python\\ndef create_ratio_features(df):\\n    df['Bilirubin_Albumin_ratio'] = df['Bilirubin'] / df['Albumin']\\n    df['SGOT_Alk_Phos_ratio'] = df['SGOT'] / df['Alk_Phos']\\n    return df\\n```\",\n",
      "    \"affected_columns\": [\"Bilirubin\", \"Albumin\", \"SGOT\", \"Alk_Phos\"],\n",
      "    \"new_features\": [\"Bilirubin_Albumin_ratio\", \"SGOT_Alk_Phos_ratio\"]\n",
      "  },\n",
      "  {\n",
      "    \"suggestion_id\": \"FE5\",\n",
      "    \"suggestion_type\": \"äº¤äº’\",\n",
      "    \"description\": \"ç»„åˆ'Stage'å’Œ'Drug'ç‰¹å¾\",\n",
      "    \"rationale\": \"ç–¾ç—…åˆ†æœŸå’Œè¯ç‰©æ²»ç–—æ–¹æ¡ˆçš„ç»„åˆå¯èƒ½å¯¹ç”Ÿå­˜ç‡æœ‰æ›´å¼ºçš„é¢„æµ‹èƒ½åŠ›ã€‚\",\n",
      "    \"implementation\": \"```python\\ndef combine_features(df):\\n    df['Stage_Drug'] = df['Stage'].astype(str) + '_' + df['Drug']\\n    return df\\n```\",\n",
      "    \"affected_columns\": [\"Stage\", \"Drug\"],\n",
      "    \"new_features\": [\"Stage_Drug\"]\n",
      "  },\n",
      "  {\n",
      "    \"suggestion_id\": \"FE6\",\n",
      "    \"suggestion_type\": \"é¢†åŸŸçŸ¥è¯†\",\n",
      "    \"description\": \"å°†'N_Days'è½¬æ¢ä¸ºç”Ÿå­˜æ—¶é—´ç±»åˆ«\",\n",
      "    \"rationale\": \"ç”Ÿå­˜æ—¶é—´æ˜¯ä¸€ä¸ªè¿ç»­å˜é‡ï¼Œå°†å…¶ç¦»æ•£åŒ–å¯èƒ½æ›´å®¹æ˜“è¢«æ¨¡å‹å­¦ä¹ ã€‚å¯ä»¥æ ¹æ®åŒ»å­¦çŸ¥è¯†æˆ–ä¸šåŠ¡éœ€æ±‚è‡ªå®šä¹‰åˆ†æ®µã€‚\",\n",
      "    \"implementation\": \"```python\\ndef categorize_survival_time(df, bins):\\n  df['Survival_Category'] = pd.cut(df['N_Days'], bins=bins, labels=False, right=False) \\n  return df\\n```\",\n",
      "    \"affected_columns\": [\"N_Days\"],\n",
      "    \"new_features\": [\"Survival_Category\"]\n",
      "  },\n",
      "  {\n",
      "    \"suggestion_id\": \"FE7\",\n",
      "    \"suggestion_type\": \"è½¬æ¢\",\n",
      "    \"description\": \"å¯¹'Stage'ç‰¹å¾è¿›è¡Œç‹¬çƒ­ç¼–ç \",\n",
      "    \"rationale\": \"'Stage'æ˜¯ç±»åˆ«ç‰¹å¾ï¼Œç‹¬çƒ­ç¼–ç å¯ä»¥é¿å…æ¨¡å‹å°†ç±»åˆ«è¿›è¡Œæ’åºã€‚\",\n",
      "    \"implementation\": \"```python\\nfrom sklearn.preprocessing import OneHotEncoder\\ndef onehot_encode_stage(df, column):\\n    encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\\n    encoded_data = encoder.fit_transform(df[[column]])\\n    encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out([column]))\\n    df = pd.concat([df, encoded_df], axis=1)\\n    return df\\n```\",\n",
      "    \"affected_columns\": [\"Stage\"],\n",
      "    \"new_features\": [\"Stage_1\", \"Stage_2\", \"Stage_3\", \"Stage_4\"]\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "=====================\n",
      "\n",
      "âš ï¸ LLMè¿”å›æ ¼å¼ä¸æ­£ç¡®ï¼Œå°è¯•æå–å»ºè®®\n",
      "\n",
      "==== å°è¯•ä»æ–‡æœ¬ä¸­æå–å»ºè®® ====\n",
      "æ–‡æœ¬é•¿åº¦: 3943 å­—ç¬¦\n",
      "å‰500ä¸ªå­—ç¬¦é¢„è§ˆ:\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"suggestion_id\": \"FE1\",\n",
      "    \"suggestion_type\": \"è½¬æ¢\",\n",
      "    \"description\": \"å°†äºŒå…ƒåˆ†ç±»ç‰¹å¾è½¬æ¢ä¸ºæ•°å€¼å‹ (0, 1)\",\n",
      "    \"rationale\": \"æ–¹ä¾¿æ¨¡å‹å¤„ç†ï¼Œé¿å…æ¨¡å‹å¯¹ç±»åˆ«é¡ºåºæ•æ„Ÿã€‚\",\n",
      "    \"implementation\": \"```python\\ndef binary_encode(df, columns):\\n    for col in columns:\\n        df[col] = df[col].map({'N': 0, 'Y': 1, 'F':0, 'M':1, 'N':0, 'S':0.5, 'Y':1, 'C':0, 'D':1, 'CL':0.5})\\n    return df\\n```\",\n",
      "    \"affected_columns\": [\"Sex\", \"Ascites\", \"Hepatomegaly\", \"Spiders\", \"Edema\"],\n",
      "    \"new_features\": [\"Sex_encoded\", \"Ascite...\n",
      "============================\n",
      "\n",
      "æ‰¾åˆ° 0 ä¸ªæ½œåœ¨çš„å»ºè®®å—\n",
      "ğŸ“ ä»æ–‡æœ¬ä¸­æå–äº†0ä¸ªå»ºè®®\n",
      "âš ï¸ æ²¡æœ‰å¯ç”¨çš„ç‰¹å¾å·¥ç¨‹å»ºè®®\n"
     ]
    }
   ],
   "source": [
    "suggestions = pipeline.ask_for_feature_suggestions(\n",
    "    df=train_eng, \n",
    "    task_description=\"é¢„æµ‹æ‚£è€…å­˜æ´»ç‡\", \n",
    "    target_column=\"Survival\", \n",
    "    dataset_background=\"è¿™æ˜¯ä¸€ä¸ªåŒ»å­¦æ•°æ®é›†ï¼ŒåŒ…å«æ‚£è€…çš„å„ç§ç”Ÿç†æŒ‡æ ‡å’Œæ²»ç–—æ–¹æ¡ˆã€‚æ•°æ®æ¥è‡ªäºæŸè‚ç—…ç ”ç©¶é¡¹ç›®...\"\n",
    ")\n",
    "enhanced_df = pipeline.implement_all_suggestions(train_eng)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
